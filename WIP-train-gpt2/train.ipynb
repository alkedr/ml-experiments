{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 13:42:45,669 INFO Starting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cudagraphs', 'inductor', 'onnxrt', 'openxla', 'tvm']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "logging.info(\"Starting\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"pszemraj/simple_wikipedia_LM\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 14900.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, decoders, models, normalizers, pre_tokenizers, trainers\n",
    "tokenizer = Tokenizer(models.Unigram())\n",
    "tokenizer.normalizer = normalizers.NFKC()\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "trainer = trainers.UnigramTrainer(\n",
    "    vocab_size=300,\n",
    "    initial_alphabet=pre_tokenizers.ByteLevel.alphabet(),\n",
    "    special_tokens=[\"<PAD>\", \"<BOS>\", \"<EOS>\"],\n",
    ")\n",
    "tokenizer.train_from_iterator(tqdm(dataset['train']['text'][:1000]), trainer=trainer)\n",
    "\n",
    "# # tokenizer = GPT2TokenizerFast.from_pretrained(\"openai-community/gpt2\", add_prefix_space=True)\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tokens.shape=torch.Size([796, 1024])\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 1024\n",
    "\n",
    "train_tokens = tokenizer.encode(\n",
    "    '\\n\\n'.join(dataset['train']['text'][:1000]),\n",
    ")\n",
    "train_tokens = torch.tensor(train_tokens.ids).reshape(1, -1)\n",
    "truncated_length = train_tokens.shape[1] // chunk_size * chunk_size\n",
    "train_tokens = train_tokens[:, :truncated_length].reshape(-1, chunk_size)\n",
    "train_tokens = train_tokens[torch.randperm(train_tokens.shape[0])]\n",
    "train_tokens = train_tokens.to(device)\n",
    "print(f\"{train_tokens.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 17:13:50,914 INFO Parameter count: 86.07M\n"
     ]
    }
   ],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    n_positions=1024,\n",
    "    n_ctx=1024,\n",
    "    n_embd=768,\n",
    "    n_layer=12,\n",
    "    n_head=12\n",
    ")\n",
    "model = GPT2LMHeadModel(config).to(device)\n",
    "model.apply(model._init_weights)\n",
    "logging.info(f\"Parameter count: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "initial_lr = 7e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=initial_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch0: 100%|██████████| 796/796 [10:12<00:00,  1.30it/s]\n",
      "epoch1: 100%|██████████| 796/796 [10:09<00:00,  1.31it/s]\n",
      "epoch2: 100%|██████████| 796/796 [09:51<00:00,  1.35it/s]\n",
      "epoch3: 100%|██████████| 796/796 [10:15<00:00,  1.29it/s]\n",
      "epoch4:   1%|          | 8/796 [00:06<11:17,  1.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     lr \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 27\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_tokens) \u001b[38;5;241m+\u001b[39m chunk_idx)\n\u001b[1;32m     28\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m'\u001b[39m, lr, epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_tokens) \u001b[38;5;241m+\u001b[39m chunk_idx)\n\u001b[1;32m     29\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime/step\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m step_start_time, epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_tokens) \u001b[38;5;241m+\u001b[39m chunk_idx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(comment=f\"{initial_lr:=.2e},tokenizer{tokenizer.get_vocab_size()}\")\n",
    "\n",
    "attention_mask = torch.ones(1, chunk_size).to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=len(train_tokens),\n",
    "        eta_min=initial_lr * 0.1,\n",
    "        last_epoch=epoch-1,\n",
    "    )\n",
    "    for chunk_idx in tqdm(range(len(train_tokens)), desc=f\"epoch{epoch}\"):\n",
    "        step_start_time = time.time()\n",
    "        chunk = train_tokens[chunk_idx, :].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=chunk,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=chunk,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if chunk_idx % 1 == 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            writer.add_scalar('Loss/train', loss.item(), epoch * len(train_tokens) + chunk_idx)\n",
    "            writer.add_scalar('Learning Rate', lr, epoch * len(train_tokens) + chunk_idx)\n",
    "            writer.add_scalar('Time/step', time.time() - step_start_time, epoch * len(train_tokens) + chunk_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
